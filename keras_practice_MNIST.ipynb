{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import all the necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "import pylab\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Convolution2D, Flatten, MaxPooling2D, Reshape, InputLayer\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let’s set a seed value, so that we can control our models randomness\n",
    "seed=128\n",
    "rng=np.random.RandomState(seed)\n",
    "\n",
    "#define vars\n",
    "input_num_units=784\n",
    "hidden_num_units1=100\n",
    "hidden_num_units2=100\n",
    "hidden_num_units3=100\n",
    "hidden_num_units4=100\n",
    "hidden_num_units5=100\n",
    "\n",
    "output_num_units=10\n",
    "\n",
    "epochs=30\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The first step is to set directory paths, for safekeeping!\n",
    "root_dir = os.path.abspath('../..')\n",
    "data_dir = os.path.join(root_dir, 'data')\n",
    "sub_dir = os.path.join(root_dir, 'sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Loading and Preprocessing\n",
    "def preprocess_data():\n",
    "    train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "    test = pd.read_csv(os.path.join(data_dir, 'Test.csv'))\n",
    "    sample_submission = pd.read_csv(os.path.join(data_dir, 'Sample_Submission.csv'))\n",
    "    return train,test,sample_submission\n",
    "\n",
    "#Let us see what our data looks like! We read our image and display it.\n",
    "def viewimage(train,dir_name):\n",
    "    img_name = rng.choice(train.filename)\n",
    "    filepath = os.path.join(data_dir,dir_name, img_name)\n",
    "    img = imread(filepath, flatten=True)\n",
    "    pylab.imshow(img, cmap='gray')\n",
    "    pylab.axis('off')\n",
    "    pylab.show()\n",
    "\n",
    "#For easier data manipulation, let’s store all our images as numpy arrays\n",
    "def imgtoarray(data,dir_name):\n",
    "    print(\"image to array\")\n",
    "    temp = []\n",
    "    for img_name in data.filename:\n",
    "        image_path = os.path.join(data_dir,dir_name, img_name)\n",
    "        img = imread(image_path, flatten=True)\n",
    "        img = img.astype('float32')\n",
    "        temp.append(img)\n",
    "    train_x = np.stack(temp)\n",
    "    train_x /= 255.0\n",
    "    train_x = train_x.reshape(-1, 784).astype('float32')\n",
    "    if(dir_name=='train'):\n",
    "        train_y = keras.utils.np_utils.to_categorical(train.label.values)\n",
    "        return train_x,train_y\n",
    "    else:\n",
    "        return  train_x\n",
    "\n",
    "#As this is a typical ML problem, to test the proper functioning of our\n",
    "# model we create a validation set.\n",
    "# Let’s take a split size of 70:30 for train set vs validation set\n",
    "def datasplit(train_x,train_y,train):\n",
    "    print(\"data split\")\n",
    "    split_size=int(train_x.shape[0]*0.7)\n",
    "    train_x,val_x=train_x[:split_size],train_x[split_size:]\n",
    "    train_y,val_y=train_y[:split_size],train_y[split_size:]\n",
    "    train.label.ix[split_size:]\n",
    "    return train_x,val_x,train_y,val_y\n",
    "\n",
    "def buildmodel(train_x,train_y,val_x,val_y,logger):\n",
    "    print(\"#Model Building\")\n",
    "    model=Sequential()\n",
    "    model.add(Dense(hidden_num_units1,input_dim=input_num_units,activation='relu'))\n",
    "    #model.add(Dense(hidden_num_units2,activation='relu'))\n",
    "    #model.add(Dense(hidden_num_units3,activation='relu'))\n",
    "    #model.add(Dense(hidden_num_units4,activation='relu'))\n",
    "    #model.add(Dense(hidden_num_units5,activation='relu'))\n",
    "    model.add(Dense(output_num_units,activation='softmax'))\n",
    "    print('compile the model with necessary attributes')\n",
    "    ## compile the model with necessary attributes\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    print('Its time to train our model')\n",
    "    #It’s time to train our model\n",
    "    trained_model=model.fit(train_x,train_y,epochs=epochs,batch_size=batch_size,validation_data=(val_x,val_y),callbacks=[logger])\n",
    "    return model\n",
    "\n",
    "def modeleval(model,test_x):\n",
    "    print('Model Evaluation')\n",
    "    #Model Evaluation\n",
    "    #To test our model with our own eyes, let’s visualize its predictions\n",
    "    pred=model.predict_classes(test_x)\n",
    "    return pred\n",
    "\n",
    "def showpred(test,train,pred):\n",
    "    print('showpred')\n",
    "    img_name=rng.choice(test.filename)\n",
    "    filepath=os.path.join(data_dir,'test',img_name)\n",
    "    img=imread(filepath,flatten=True)\n",
    "    test_index=int(img_name.split('.')[0]) - train.shape[0]\n",
    "    print('\\nprediction is:', pred[test_index])\n",
    "    pylab.imshow(img,cmap='gray')\n",
    "    pylab.axis('off')\n",
    "    pylab.show()\n",
    "\n",
    "def save_model(model,name):\n",
    "\t# Save the model to disk\n",
    "\tmodel.save(name)\n",
    "\tprint(\"Model saved to disk.\")\n",
    "\n",
    "def model_load(model,name):\n",
    "\tmodel = load_model(name)\n",
    "\treturn model\n",
    "\n",
    "def tensorboard_logger(RUN_NAME,histogram_freq=5,write_graph=True):\n",
    "\t# Create a TensorBoard logger\n",
    "\tlogger = keras.callbacks.TensorBoard(\n",
    "\t    log_dir='logs/{}'.format(RUN_NAME),\n",
    "\t    histogram_freq=histogram_freq,\n",
    "\t    write_graph=write_graph )\n",
    "\treturn logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# train,test,sample_submission=preprocess_data()\n",
    "#\n",
    "# viewimage(train,dir_name='train')\n",
    "#\n",
    "# train_x,train_y=imgtoarray(train,dir_name='train')\n",
    "#\n",
    "# test_x=imgtoarray(test,dir_name='test')\n",
    "#\n",
    "# train_x,val_x,train_y,val_y=datasplit(train_x,train_y,train)\n",
    "#\n",
    "# logger=tensorboard_logger(RUN_NAME='model with one layer and epoch{}'.format(epochs))\n",
    "#\n",
    "# model=buildmodel(train_x,train_y,val_x,val_y,logger)\n",
    "#\n",
    "# save_model(model,'prac2.h5')\n",
    "#\n",
    "# pred=modeleval(model,test_x)\n",
    "#\n",
    "# showpred(test,train,pred)\n",
    "\n",
    "\n",
    "#you can visualize the result on tesorboard by using the command on terminal as tensorboard --logdir=logs\n",
    "#feel free to experiment with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is how we reuse the pre train model and make the prediction from it.\n",
    "\n",
    "train,test,sample_submission=preprocess_data()\n",
    "\n",
    "model = load_model('prac2.h5')\n",
    "\n",
    "test_x=imgtoarray(test,dir_name='test')\n",
    "\n",
    "pred=modeleval(model,test_x)\n",
    "\n",
    "showpred(test,train,pred)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
